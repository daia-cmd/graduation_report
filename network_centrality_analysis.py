#!/usr/bin/env python3
"""
ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§åˆ†æž

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œï¼š
1. å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
2. ä¸­å¿ƒæ€§æŒ‡æ¨™ã®è¨ˆç®—ï¼ˆPageRank, Degree, Betweennessï¼‰
3. ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆä¸­å¿ƒæ€§
4. ãƒˆãƒƒãƒ—å›½ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
5. æ™‚ç³»åˆ—ã§ã®å¤‰åŒ–åˆ†æž
6. å¯è¦–åŒ–

ä½¿ç”¨æ–¹æ³•ï¼š
  python network_centrality_analysis.py
"""

import pandas as pd
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# ã‚°ãƒ©ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

print("="*70)
print(" ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§åˆ†æž ")
print("="*70)

# =====================================================================
# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =====================================================================
print("\n[1] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")

data_paths = [
    Path('data/raw/multilayer_network.csv'),
    Path('multilayer_network.csv')
]

df = None
for data_path in data_paths:
    if data_path.exists():
        df = pd.read_csv(data_path)
        print(f"  âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {data_path}")
        break

if df is None:
    print("  âœ— ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    exit(1)

print(f"  ç·è¡Œæ•°: {len(df):,}")
print(f"  å¹´: {sorted(df['year'].unique())}")

layers = ['diplomatic_relation', 'aviation_routes', 'migrant_stock']
layer_names = {
    'diplomatic_relation': 'Diplomatic',
    'aviation_routes': 'Aviation',
    'migrant_stock': 'Migration'
}

# å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª
OUTPUT_DIRS = {
    'figures': Path('outputs/figures'),
    'tables': Path('outputs/tables'),
    'reports': Path('outputs/reports')
}

for path in OUTPUT_DIRS.values():
    path.mkdir(parents=True, exist_ok=True)

# =====================================================================
# 2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰é–¢æ•°
# =====================================================================
print("\n[2] ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰é–¢æ•°å®šç¾©...")

def build_network(data, layer, weighted=True):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰
    
    Parameters:
    -----------
    data : DataFrame
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿
    layer : str
        ãƒ¬ã‚¤ãƒ¤ãƒ¼å
    weighted : bool
        é‡ã¿ä»˜ãã‚°ãƒ©ãƒ•ã‹ã©ã†ã‹
    
    Returns:
    --------
    G : nx.DiGraph
        æ§‹ç¯‰ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    """
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿
    layer_data = data[data[layer].notna()].copy()
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
    G = nx.DiGraph()
    
    for _, row in layer_data.iterrows():
        origin = row['origin']
        destination = row['destination']
        weight = row[layer]
        
        if weighted:
            if G.has_edge(origin, destination):
                # æ—¢å­˜ã®ã‚¨ãƒƒã‚¸ã®é‡ã¿ã‚’åŠ ç®—
                G[origin][destination]['weight'] += weight
            else:
                G.add_edge(origin, destination, weight=weight)
        else:
            G.add_edge(origin, destination)
    
    return G

def calculate_centralities(G, weighted=True):
    """
    ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸­å¿ƒæ€§æŒ‡æ¨™ã‚’è¨ˆç®—
    
    Parameters:
    -----------
    G : nx.DiGraph
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    weighted : bool
        é‡ã¿ä»˜ãä¸­å¿ƒæ€§ã‚’è¨ˆç®—ã™ã‚‹ã‹
    
    Returns:
    --------
    centralities : dict
        å„ä¸­å¿ƒæ€§æŒ‡æ¨™ã®è¾žæ›¸
    """
    centralities = {}
    
    # PageRank
    try:
        if weighted and nx.is_weighted(G):
            centralities['pagerank'] = nx.pagerank(G, weight='weight')
        else:
            centralities['pagerank'] = nx.pagerank(G)
    except:
        centralities['pagerank'] = {}
    
    # In-Degreeï¼ˆå…¥æ¬¡æ•°ï¼‰
    if weighted and nx.is_weighted(G):
        centralities['in_degree'] = dict(G.in_degree(weight='weight'))
    else:
        centralities['in_degree'] = dict(G.in_degree())
    
    # Out-Degreeï¼ˆå‡ºæ¬¡æ•°ï¼‰
    if weighted and nx.is_weighted(G):
        centralities['out_degree'] = dict(G.out_degree(weight='weight'))
    else:
        centralities['out_degree'] = dict(G.out_degree())
    
    # Betweenness Centralityï¼ˆåª’ä»‹ä¸­å¿ƒæ€§ï¼‰
    try:
        if weighted and nx.is_weighted(G):
            centralities['betweenness'] = nx.betweenness_centrality(
                G, weight='weight')
        else:
            centralities['betweenness'] = nx.betweenness_centrality(G)
    except:
        centralities['betweenness'] = {}
    
    # Closeness Centralityï¼ˆè¿‘æŽ¥ä¸­å¿ƒæ€§ï¼‰
    try:
        centralities['closeness'] = nx.closeness_centrality(G)
    except:
        centralities['closeness'] = {}
    
    return centralities

print("  âœ“ é–¢æ•°å®šç¾©å®Œäº†")

# =====================================================================
# 3. å„å¹´ãƒ»å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä¸­å¿ƒæ€§è¨ˆç®—
# =====================================================================
print("\n[3] ä¸­å¿ƒæ€§è¨ˆç®—ä¸­...")

years = sorted(df['year'].unique())
all_centralities = {}

for year in years:
    print(f"\n  â–  {year}å¹´")
    df_year = df[df['year'] == year]
    all_centralities[year] = {}
    
    for layer in layers:
        print(f"    - {layer_names[layer]}ãƒ¬ã‚¤ãƒ¤ãƒ¼...")
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
        G = build_network(df_year, layer, weighted=True)
        
        print(f"      ãƒŽãƒ¼ãƒ‰æ•°: {G.number_of_nodes()}")
        print(f"      ã‚¨ãƒƒã‚¸æ•°: {G.number_of_edges()}")
        
        # ä¸­å¿ƒæ€§è¨ˆç®—
        centralities = calculate_centralities(G, weighted=True)
        
        all_centralities[year][layer] = {
            'network': G,
            'centralities': centralities
        }

print("\n  âœ“ ä¸­å¿ƒæ€§è¨ˆç®—å®Œäº†")

# =====================================================================
# 4. ãƒˆãƒƒãƒ—å›½ãƒ©ãƒ³ã‚­ãƒ³ã‚°
# =====================================================================
print("\n[4] ãƒˆãƒƒãƒ—å›½ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆä¸­...")

def get_top_countries(centralities, metric='pagerank', n=20):
    """
    æŒ‡å®šã•ã‚ŒãŸä¸­å¿ƒæ€§æŒ‡æ¨™ã§ãƒˆãƒƒãƒ—Nå›½ã‚’å–å¾—
    """
    if metric not in centralities or not centralities[metric]:
        return []
    
    sorted_countries = sorted(centralities[metric].items(), 
                             key=lambda x: x[1], reverse=True)
    return sorted_countries[:n]

# æœ€æ–°å¹´ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤º
latest_year = max(years)
print(f"\nã€{latest_year}å¹´ã®ãƒˆãƒƒãƒ—20ã‚«å›½ã€‘")
print("-"*70)

for layer in layers:
    print(f"\nâ–  {layer_names[layer]}ãƒ¬ã‚¤ãƒ¤ãƒ¼ (PageRank)")
    
    centralities = all_centralities[latest_year][layer]['centralities']
    top_countries = get_top_countries(centralities, 'pagerank', 20)
    
    for rank, (country, score) in enumerate(top_countries, 1):
        print(f"  {rank:2d}. {country:3s}: {score:.6f}")

# =====================================================================
# 5. ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆä¸­å¿ƒæ€§
# =====================================================================
print("\n[5] ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆä¸­å¿ƒæ€§è¨ˆç®—ä¸­...")

multilayer_centrality = {}

for year in years:
    # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®PageRankã‚’æ­£è¦åŒ–ã—ã¦çµ±åˆ
    all_countries = set()
    
    # å…¨ã¦ã®å›½ã‚’åŽé›†
    for layer in layers:
        centralities = all_centralities[year][layer]['centralities']
        all_countries.update(centralities['pagerank'].keys())
    
    # çµ±åˆã‚¹ã‚³ã‚¢è¨ˆç®—
    integrated_scores = {}
    
    for country in all_countries:
        scores = []
        
        for layer in layers:
            centralities = all_centralities[year][layer]['centralities']
            score = centralities['pagerank'].get(country, 0)
            scores.append(score)
        
        # å¹³å‡ï¼ˆç­‰é‡ã¿ï¼‰
        integrated_scores[country] = np.mean(scores)
    
    multilayer_centrality[year] = integrated_scores

print(f"\nã€{latest_year}å¹´ã®ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆä¸­å¿ƒæ€§ãƒˆãƒƒãƒ—20ã€‘")
print("-"*70)

sorted_countries = sorted(multilayer_centrality[latest_year].items(),
                         key=lambda x: x[1], reverse=True)

for rank, (country, score) in enumerate(sorted_countries[:20], 1):
    print(f"  {rank:2d}. {country:3s}: {score:.6f}")

# =====================================================================
# 6. ä¸­å¿ƒæ€§ã®æ™‚ç³»åˆ—å¤‰åŒ–
# =====================================================================
print("\n[6] ä¸­å¿ƒæ€§ã®æ™‚ç³»åˆ—å¤‰åŒ–åˆ†æžä¸­...")

# ãƒˆãƒƒãƒ—10ã‚«å›½ã‚’é¸æŠžï¼ˆæœ€æ–°å¹´ã®ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼ä¸­å¿ƒæ€§ï¼‰
top10_countries = [country for country, _ in sorted_countries[:10]]

# å„å›½ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’åŽé›†
time_series_data = []

for country in top10_countries:
    for year in years:
        score = multilayer_centrality[year].get(country, 0)
        time_series_data.append({
            'Country': country,
            'Year': year,
            'Centrality': score
        })

ts_df = pd.DataFrame(time_series_data)

# =====================================================================
# 7. å¯è¦–åŒ–
# =====================================================================
print("\n[7] å¯è¦–åŒ–ç”Ÿæˆä¸­...")

# ----- å›³7: ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ãƒˆãƒƒãƒ—10å›½ï¼ˆæœ€æ–°å¹´ï¼‰ -----
print("  [å›³7] ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ãƒˆãƒƒãƒ—10å›½...")

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, layer in enumerate(layers):
    centralities = all_centralities[latest_year][layer]['centralities']
    top_countries = get_top_countries(centralities, 'pagerank', 10)
    
    countries = [c for c, _ in top_countries]
    scores = [s for _, s in top_countries]
    
    axes[idx].barh(range(len(countries)), scores, color='steelblue', alpha=0.8)
    axes[idx].set_yticks(range(len(countries)))
    axes[idx].set_yticklabels(countries, fontsize=10)
    axes[idx].set_xlabel('PageRank', fontsize=11, fontweight='bold')
    axes[idx].set_title(f'{layer_names[layer]} Layer ({latest_year})', 
                       fontsize=12, fontweight='bold')
    axes[idx].invert_yaxis()
    axes[idx].grid(True, alpha=0.3, axis='x')

plt.tight_layout()
fig_path = OUTPUT_DIRS['figures'] / 'fig7_top10_by_layer.png'
plt.savefig(fig_path, dpi=300, bbox_inches='tight')
print(f"    âœ“ {fig_path}")
plt.close()

# ----- å›³8: ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆä¸­å¿ƒæ€§ãƒˆãƒƒãƒ—20 -----
print("  [å›³8] ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆä¸­å¿ƒæ€§ãƒˆãƒƒãƒ—20...")

fig, ax = plt.subplots(figsize=(10, 8))

top20 = sorted_countries[:20]
countries = [c for c, _ in top20]
scores = [s for _, s in top20]

ax.barh(range(len(countries)), scores, color='coral', alpha=0.8, edgecolor='black')
ax.set_yticks(range(len(countries)))
ax.set_yticklabels(countries, fontsize=11)
ax.set_xlabel('Integrated Centrality Score', fontsize=12, fontweight='bold')
ax.set_title(f'Top 20 Countries: Multilayer Centrality ({latest_year})', 
             fontsize=14, fontweight='bold')
ax.invert_yaxis()
ax.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
fig_path = OUTPUT_DIRS['figures'] / 'fig8_multilayer_top20.png'
plt.savefig(fig_path, dpi=300, bbox_inches='tight')
print(f"    âœ“ {fig_path}")
plt.close()

# ----- å›³9: ãƒˆãƒƒãƒ—10å›½ã®æ™‚ç³»åˆ—å¤‰åŒ– -----
print("  [å›³9] ãƒˆãƒƒãƒ—10å›½ã®æ™‚ç³»åˆ—å¤‰åŒ–...")

fig, ax = plt.subplots(figsize=(12, 7))

for country in top10_countries:
    country_data = ts_df[ts_df['Country'] == country]
    ax.plot(country_data['Year'], country_data['Centrality'], 
           marker='o', linewidth=2, markersize=6, label=country)

ax.set_xlabel('Year', fontsize=12, fontweight='bold')
ax.set_ylabel('Multilayer Centrality', fontsize=12, fontweight='bold')
ax.set_title('Time Series: Top 10 Countries Centrality', 
            fontsize=14, fontweight='bold')
ax.legend(loc='best', fontsize=10, ncol=2)
ax.grid(True, alpha=0.3)
ax.set_xticks(years)

plt.tight_layout()
fig_path = OUTPUT_DIRS['figures'] / 'fig9_centrality_time_series.png'
plt.savefig(fig_path, dpi=300, bbox_inches='tight')
print(f"    âœ“ {fig_path}")
plt.close()

# ----- å›³10: ä¸­å¿ƒæ€§æŒ‡æ¨™ã®æ¯”è¼ƒï¼ˆæœ€æ–°å¹´ï¼‰ -----
print("  [å›³10] ä¸­å¿ƒæ€§æŒ‡æ¨™ã®æ¯”è¼ƒ...")

# å¤–äº¤ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®è¤‡æ•°æŒ‡æ¨™ã‚’æ¯”è¼ƒ
layer = 'diplomatic_relation'
centralities = all_centralities[latest_year][layer]['centralities']

metrics = ['pagerank', 'in_degree', 'betweenness']
metric_names = ['PageRank', 'In-Degree', 'Betweenness']

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, (metric, name) in enumerate(zip(metrics, metric_names)):
    if metric in centralities and centralities[metric]:
        top = sorted(centralities[metric].items(), 
                    key=lambda x: x[1], reverse=True)[:10]
        
        countries = [c for c, _ in top]
        scores = [s for _, s in top]
        
        axes[idx].barh(range(len(countries)), scores, 
                      color='lightseagreen', alpha=0.8)
        axes[idx].set_yticks(range(len(countries)))
        axes[idx].set_yticklabels(countries, fontsize=10)
        axes[idx].set_xlabel(name, fontsize=11, fontweight='bold')
        axes[idx].set_title(f'{name} - {layer_names[layer]} ({latest_year})', 
                          fontsize=12, fontweight='bold')
        axes[idx].invert_yaxis()
        axes[idx].grid(True, alpha=0.3, axis='x')

plt.tight_layout()
fig_path = OUTPUT_DIRS['figures'] / 'fig10_centrality_metrics_comparison.png'
plt.savefig(fig_path, dpi=300, bbox_inches='tight')
print(f"    âœ“ {fig_path}")
plt.close()

# ----- å›³11: ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“ã®ä¸­å¿ƒæ€§ç›¸é–¢ï¼ˆæœ€æ–°å¹´ï¼‰ -----
print("  [å›³11] ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“ã®ä¸­å¿ƒæ€§ç›¸é–¢...")

# å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®PageRankã‚’åŽé›†
all_countries = set()
for layer in layers:
    centralities = all_centralities[latest_year][layer]['centralities']
    all_countries.update(centralities['pagerank'].keys())

centrality_comparison = []

for country in all_countries:
    row = {'Country': country}
    
    for layer in layers:
        centralities = all_centralities[latest_year][layer]['centralities']
        row[layer_names[layer]] = centralities['pagerank'].get(country, 0)
    
    centrality_comparison.append(row)

comp_df = pd.DataFrame(centrality_comparison)

# ç›¸é–¢è¡Œåˆ—
corr_matrix = comp_df[['Diplomatic', 'Aviation', 'Migration']].corr(method='spearman')

fig, ax = plt.subplots(figsize=(8, 6))

sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm',
           center=0, vmin=-1, vmax=1, square=True,
           cbar_kws={'shrink': 0.8}, ax=ax,
           linewidths=1, linecolor='black')

ax.set_title(f'Layer Centrality Correlation ({latest_year})', 
            fontsize=14, fontweight='bold')

plt.tight_layout()
fig_path = OUTPUT_DIRS['figures'] / 'fig11_layer_centrality_correlation.png'
plt.savefig(fig_path, dpi=300, bbox_inches='tight')
print(f"    âœ“ {fig_path}")
plt.close()

# ----- å›³12: ä¸­å¿ƒæ€§ã®ãƒ©ãƒ³ã‚¯å¤‰åŒ–ï¼ˆ2000 vs 2020ï¼‰ -----
print("  [å›³12] ä¸­å¿ƒæ€§ã®ãƒ©ãƒ³ã‚¯å¤‰åŒ–...")

if 2000 in years and 2020 in years:
    # 2000å¹´ã¨2020å¹´ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    rank_2000 = sorted(multilayer_centrality[2000].items(),
                      key=lambda x: x[1], reverse=True)
    rank_2020 = sorted(multilayer_centrality[2020].items(),
                      key=lambda x: x[1], reverse=True)
    
    # ãƒˆãƒƒãƒ—20ã®å›½ã‚’é¸æŠž
    top20_2000 = set([c for c, _ in rank_2000[:20]])
    top20_2020 = set([c for c, _ in rank_2020[:20]])
    top20_union = top20_2000.union(top20_2020)
    
    # ãƒ©ãƒ³ã‚¯å¤‰åŒ–ã‚’è¨ˆç®—
    rank_changes = []
    
    for country in top20_union:
        rank_2000_val = next((i+1 for i, (c, _) in enumerate(rank_2000) 
                             if c == country), None)
        rank_2020_val = next((i+1 for i, (c, _) in enumerate(rank_2020) 
                             if c == country), None)
        
        if rank_2000_val and rank_2020_val:
            change = rank_2000_val - rank_2020_val  # æ­£=ä¸Šæ˜‡
            rank_changes.append({
                'Country': country,
                'Rank_2000': rank_2000_val,
                'Rank_2020': rank_2020_val,
                'Change': change
            })
    
    rank_changes_df = pd.DataFrame(rank_changes)
    rank_changes_df = rank_changes_df.sort_values('Change', ascending=False)
    
    # å¯è¦–åŒ–
    fig, ax = plt.subplots(figsize=(12, 8))
    
    top_gainers = rank_changes_df.head(10)
    top_losers = rank_changes_df.tail(10).iloc[::-1]
    
    plot_data = pd.concat([top_gainers, top_losers])
    
    colors = ['green' if x > 0 else 'red' for x in plot_data['Change']]
    
    ax.barh(range(len(plot_data)), plot_data['Change'], 
           color=colors, alpha=0.7, edgecolor='black')
    ax.set_yticks(range(len(plot_data)))
    ax.set_yticklabels(plot_data['Country'], fontsize=10)
    ax.set_xlabel('Rank Change (2000â†’2020)', fontsize=12, fontweight='bold')
    ax.set_title('Top Gainers and Losers in Centrality Ranking', 
                fontsize=14, fontweight='bold')
    ax.axvline(0, color='black', linewidth=1)
    ax.grid(True, alpha=0.3, axis='x')
    
    plt.tight_layout()
    fig_path = OUTPUT_DIRS['figures'] / 'fig12_rank_changes_2000_2020.png'
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    print(f"    âœ“ {fig_path}")
    plt.close()

# =====================================================================
# 8. çµ±è¨ˆè¡¨ã®ä¿å­˜
# =====================================================================
print("\n[8] çµ±è¨ˆè¡¨ä¿å­˜ä¸­...")

# æœ€æ–°å¹´ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ãƒˆãƒƒãƒ—20
for layer in layers:
    centralities = all_centralities[latest_year][layer]['centralities']
    top20 = get_top_countries(centralities, 'pagerank', 20)
    
    df_top20 = pd.DataFrame(top20, columns=['Country', 'PageRank'])
    df_top20['Rank'] = range(1, len(df_top20) + 1)
    df_top20 = df_top20[['Rank', 'Country', 'PageRank']]
    
    filename = f'centrality_{layer}_{latest_year}.csv'
    output_path = OUTPUT_DIRS['tables'] / filename
    df_top20.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"  âœ“ {output_path}")

# ãƒžãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆä¸­å¿ƒæ€§ãƒˆãƒƒãƒ—20
df_multilayer = pd.DataFrame(sorted_countries[:20], 
                            columns=['Country', 'Centrality'])
df_multilayer['Rank'] = range(1, 21)
df_multilayer = df_multilayer[['Rank', 'Country', 'Centrality']]

output_path = OUTPUT_DIRS['tables'] / f'centrality_multilayer_{latest_year}.csv'
df_multilayer.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"  âœ“ {output_path}")

# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
output_path = OUTPUT_DIRS['tables'] / 'centrality_time_series.csv'
ts_df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"  âœ“ {output_path}")

# ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“ç›¸é–¢
output_path = OUTPUT_DIRS['tables'] / f'layer_centrality_correlation_{latest_year}.csv'
corr_matrix.to_csv(output_path, encoding='utf-8-sig')
print(f"  âœ“ {output_path}")

# =====================================================================
# 9. ã‚µãƒžãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
# =====================================================================
print("\n[9] ã‚µãƒžãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")

report_path = OUTPUT_DIRS['reports'] / 'network_centrality_report.txt'

with open(report_path, 'w', encoding='utf-8') as f:
    f.write("="*70 + "\n")
    f.write(" NETWORK CENTRALITY ANALYSIS REPORT\n")
    f.write("="*70 + "\n\n")
    
    f.write("1. ANALYSIS OVERVIEW\n")
    f.write("-"*70 + "\n")
    f.write(f"Analysis Period: {min(years)} - {max(years)}\n")
    f.write(f"Number of Years: {len(years)}\n")
    f.write(f"Layers Analyzed: {len(layers)}\n\n")
    
    f.write("2. TOP 20 COUNTRIES (MULTILAYER CENTRALITY)\n")
    f.write("-"*70 + "\n")
    f.write(f"Year: {latest_year}\n\n")
    
    for rank, (country, score) in enumerate(sorted_countries[:20], 1):
        f.write(f"{rank:2d}. {country:3s}: {score:.6f}\n")
    
    f.write("\n3. TOP 10 BY LAYER\n")
    f.write("-"*70 + "\n")
    
    for layer in layers:
        f.write(f"\n{layer_names[layer]} Layer:\n")
        centralities = all_centralities[latest_year][layer]['centralities']
        top10 = get_top_countries(centralities, 'pagerank', 10)
        
        for rank, (country, score) in enumerate(top10, 1):
            f.write(f"  {rank:2d}. {country:3s}: {score:.6f}\n")
    
    f.write("\n4. LAYER CENTRALITY CORRELATION\n")
    f.write("-"*70 + "\n")
    f.write(f"Year: {latest_year}\n\n")
    f.write(corr_matrix.to_string())
    f.write("\n\n")
    
    f.write("5. KEY FINDINGS\n")
    f.write("-"*70 + "\n")
    
    # ç›¸é–¢åˆ†æž
    diplo_avia_corr = corr_matrix.loc['Diplomatic', 'Aviation']
    diplo_migr_corr = corr_matrix.loc['Diplomatic', 'Migration']
    avia_migr_corr = corr_matrix.loc['Aviation', 'Migration']
    
    f.write(f"- Diplomatic-Aviation correlation: {diplo_avia_corr:.3f}\n")
    f.write(f"- Diplomatic-Migration correlation: {diplo_migr_corr:.3f}\n")
    f.write(f"- Aviation-Migration correlation: {avia_migr_corr:.3f}\n\n")
    
    if avia_migr_corr > 0.5:
        f.write("â†’ Strong correlation between Aviation and Migration centrality\n")
    
    if abs(diplo_avia_corr) < 0.3 and abs(diplo_migr_corr) < 0.3:
        f.write("â†’ Diplomatic centrality is relatively independent from other layers\n")
    
    f.write("\n" + "="*70 + "\n")

print(f"  âœ“ {report_path}")

# =====================================================================
# å®Œäº†
# =====================================================================
print("\n" + "="*70)
print(" âœ“ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§åˆ†æžå®Œäº†ï¼ ")
print("="*70)

print("\nã€ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã€‘")

print(f"\nðŸ“ˆ ã‚°ãƒ©ãƒ• ({OUTPUT_DIRS['figures']}):")
print("   - fig7_top10_by_layer.png")
print("   - fig8_multilayer_top20.png")
print("   - fig9_centrality_time_series.png")
print("   - fig10_centrality_metrics_comparison.png")
print("   - fig11_layer_centrality_correlation.png")
print("   - fig12_rank_changes_2000_2020.png")

print(f"\nðŸ“Š çµ±è¨ˆè¡¨ ({OUTPUT_DIRS['tables']}):")
print(f"   - centrality_diplomatic_relation_{latest_year}.csv")
print(f"   - centrality_aviation_routes_{latest_year}.csv")
print(f"   - centrality_migrant_stock_{latest_year}.csv")
print(f"   - centrality_multilayer_{latest_year}.csv")
print("   - centrality_time_series.csv")
print(f"   - layer_centrality_correlation_{latest_year}.csv")

print(f"\nðŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ ({OUTPUT_DIRS['reports']}):")
print("   - network_centrality_report.txt")

print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  1. outputs/figures/ ã®ã‚°ãƒ©ãƒ•ã‚’ç¢ºèª")
print("  2. ãƒˆãƒƒãƒ—å›½ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’åˆ†æž")
print("  3. ç›¸é–¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è§£é‡ˆ")
print("  4. è«–æ–‡ã®Resultsã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åŸ·ç­†")

print("\n" + "="*70)